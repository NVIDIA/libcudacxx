// -*- C++ -*-
//===--------------------------- mutex ------------------------------------===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//

#ifndef _LIBCUDACXX_MUTEX
#define _LIBCUDACXX_MUTEX

/*
    mutex synopsis

namespace std
{

class mutex
{
public:
     constexpr mutex() noexcept;
     ~mutex();

    mutex(const mutex&) = delete;
    mutex& operator=(const mutex&) = delete;

    void lock();
    bool try_lock();
    void unlock();

    typedef pthread_mutex_t* native_handle_type;
    native_handle_type native_handle();
};

class recursive_mutex
{
public:
     recursive_mutex();
     ~recursive_mutex();

    recursive_mutex(const recursive_mutex&) = delete;
    recursive_mutex& operator=(const recursive_mutex&) = delete;

    void lock();
    bool try_lock() noexcept;
    void unlock();

    typedef pthread_mutex_t* native_handle_type;
    native_handle_type native_handle();
};

class timed_mutex
{
public:
     timed_mutex();
     ~timed_mutex();

    timed_mutex(const timed_mutex&) = delete;
    timed_mutex& operator=(const timed_mutex&) = delete;

    void lock();
    bool try_lock();
    template <class Rep, class Period>
        bool try_lock_for(const chrono::duration<Rep, Period>& rel_time);
    template <class Clock, class Duration>
        bool try_lock_until(const chrono::time_point<Clock, Duration>& abs_time);
    void unlock();
};

class recursive_timed_mutex
{
public:
     recursive_timed_mutex();
     ~recursive_timed_mutex();

    recursive_timed_mutex(const recursive_timed_mutex&) = delete;
    recursive_timed_mutex& operator=(const recursive_timed_mutex&) = delete;

    void lock();
    bool try_lock() noexcept;
    template <class Rep, class Period>
        bool try_lock_for(const chrono::duration<Rep, Period>& rel_time);
    template <class Clock, class Duration>
        bool try_lock_until(const chrono::time_point<Clock, Duration>& abs_time);
    void unlock();
};

struct defer_lock_t { explicit defer_lock_t() = default; };
struct try_to_lock_t { explicit try_to_lock_t() = default; };
struct adopt_lock_t { explicit adopt_lock_t() = default; };

inline constexpr defer_lock_t  defer_lock{};
inline constexpr try_to_lock_t try_to_lock{};
inline constexpr adopt_lock_t  adopt_lock{};

template <class Mutex>
class lock_guard
{
public:
    typedef Mutex mutex_type;

    explicit lock_guard(mutex_type& m);
    lock_guard(mutex_type& m, adopt_lock_t);
    ~lock_guard();

    lock_guard(lock_guard const&) = delete;
    lock_guard& operator=(lock_guard const&) = delete;
};

template <class... MutexTypes>
class scoped_lock // C++17
{
public:
    using mutex_type = Mutex;  // If MutexTypes... consists of the single type Mutex

    explicit scoped_lock(MutexTypes&... m);
    scoped_lock(adopt_lock_t, MutexTypes&... m);
    ~scoped_lock();
    scoped_lock(scoped_lock const&) = delete;
    scoped_lock& operator=(scoped_lock const&) = delete;
private:
    tuple<MutexTypes&...> pm; // exposition only
};

template <class Mutex>
class unique_lock
{
public:
    typedef Mutex mutex_type;
    unique_lock() noexcept;
    explicit unique_lock(mutex_type& m);
    unique_lock(mutex_type& m, defer_lock_t) noexcept;
    unique_lock(mutex_type& m, try_to_lock_t);
    unique_lock(mutex_type& m, adopt_lock_t);
    template <class Clock, class Duration>
        unique_lock(mutex_type& m, const chrono::time_point<Clock, Duration>& abs_time);
    template <class Rep, class Period>
        unique_lock(mutex_type& m, const chrono::duration<Rep, Period>& rel_time);
    ~unique_lock();

    unique_lock(unique_lock const&) = delete;
    unique_lock& operator=(unique_lock const&) = delete;

    unique_lock(unique_lock&& u) noexcept;
    unique_lock& operator=(unique_lock&& u) noexcept;

    void lock();
    bool try_lock();

    template <class Rep, class Period>
        bool try_lock_for(const chrono::duration<Rep, Period>& rel_time);
    template <class Clock, class Duration>
        bool try_lock_until(const chrono::time_point<Clock, Duration>& abs_time);

    void unlock();

    void swap(unique_lock& u) noexcept;
    mutex_type* release() noexcept;

    bool owns_lock() const noexcept;
    explicit operator bool () const noexcept;
    mutex_type* mutex() const noexcept;
};

template <class Mutex>
  void swap(unique_lock<Mutex>& x, unique_lock<Mutex>& y) noexcept;

template <class L1, class L2, class... L3>
  int try_lock(L1&, L2&, L3&...);
template <class L1, class L2, class... L3>
  void lock(L1&, L2&, L3&...);

struct once_flag
{
    constexpr once_flag() noexcept;

    once_flag(const once_flag&) = delete;
    once_flag& operator=(const once_flag&) = delete;
};

template<class Callable, class ...Args>
  void call_once(once_flag& flag, Callable&& func, Args&&... args);

}  // std

*/

#ifndef __cuda_std__
#include <__config>
#include <__mutex_base>
#include <cstdint>
#include <functional>
#include <memory>
#ifndef _LIBCUDACXX_CXX03_LANG
#include <tuple>
#endif
#include <version>
#include <__threading_support>

#if defined(_LIBCUDACXX_USE_PRAGMA_GCC_SYSTEM_HEADER)
#pragma GCC system_header
#endif

_LIBCUDACXX_PUSH_MACROS
#include <__undef_macros>
#endif


_LIBCUDACXX_BEGIN_NAMESPACE_STD

#ifndef _LIBCUDACXX_HAS_NO_THREADS
#ifndef _LIBCUDACXX_HAS_THREAD_API_CUDA

class _LIBCUDACXX_TYPE_VIS recursive_mutex
{
    __libcpp_recursive_mutex_t __m_;

public:
     recursive_mutex();
     ~recursive_mutex();

private:
    recursive_mutex(const recursive_mutex&); // = delete;
    recursive_mutex& operator=(const recursive_mutex&); // = delete;

public:
    void lock();
    bool try_lock() _NOEXCEPT;
    void unlock()  _NOEXCEPT;

    typedef __libcpp_recursive_mutex_t* native_handle_type;

    _LIBCUDACXX_INLINE_VISIBILITY
    native_handle_type native_handle() {return &__m_;}
};

class _LIBCUDACXX_TYPE_VIS timed_mutex
{
    mutex              __m_;
    condition_variable __cv_;
    bool               __locked_;
public:
     timed_mutex();
     ~timed_mutex();

private:
    timed_mutex(const timed_mutex&); // = delete;
    timed_mutex& operator=(const timed_mutex&); // = delete;

public:
    void lock();
    bool try_lock() _NOEXCEPT;
    template <class _Rep, class _Period>
        _LIBCUDACXX_INLINE_VISIBILITY
        bool try_lock_for(const chrono::duration<_Rep, _Period>& __d)
            {return try_lock_until(chrono::steady_clock::now() + __d);}
    template <class _Clock, class _Duration>
        _LIBCUDACXX_METHOD_TEMPLATE_IMPLICIT_INSTANTIATION_VIS
        bool try_lock_until(const chrono::time_point<_Clock, _Duration>& __t);
    void unlock() _NOEXCEPT;
};

template <class _Clock, class _Duration>
bool
timed_mutex::try_lock_until(const chrono::time_point<_Clock, _Duration>& __t)
{
    using namespace chrono;
    unique_lock<mutex> __lk(__m_);
    bool no_timeout = _Clock::now() < __t;
    while (no_timeout && __locked_)
        no_timeout = __cv_.wait_until(__lk, __t) == cv_status::no_timeout;
    if (!__locked_)
    {
        __locked_ = true;
        return true;
    }
    return false;
}

class _LIBCUDACXX_TYPE_VIS recursive_timed_mutex
{
    mutex              __m_;
    condition_variable __cv_;
    size_t             __count_;
    __thread_id        __id_;
public:
     recursive_timed_mutex();
     ~recursive_timed_mutex();

private:
    recursive_timed_mutex(const recursive_timed_mutex&); // = delete;
    recursive_timed_mutex& operator=(const recursive_timed_mutex&); // = delete;

public:
    void lock();
    bool try_lock() _NOEXCEPT;
    template <class _Rep, class _Period>
        _LIBCUDACXX_INLINE_VISIBILITY
        bool try_lock_for(const chrono::duration<_Rep, _Period>& __d)
            {return try_lock_until(chrono::steady_clock::now() + __d);}
    template <class _Clock, class _Duration>
        _LIBCUDACXX_METHOD_TEMPLATE_IMPLICIT_INSTANTIATION_VIS
        bool try_lock_until(const chrono::time_point<_Clock, _Duration>& __t);
    void unlock() _NOEXCEPT;
};

template <class _Clock, class _Duration>
bool
recursive_timed_mutex::try_lock_until(const chrono::time_point<_Clock, _Duration>& __t)
{
    using namespace chrono;
    __thread_id __id = this_thread::get_id();
    unique_lock<mutex> lk(__m_);
    if (__id == __id_)
    {
        if (__count_ == numeric_limits<size_t>::max())
            return false;
        ++__count_;
        return true;
    }
    bool no_timeout = _Clock::now() < __t;
    while (no_timeout && __count_ != 0)
        no_timeout = __cv_.wait_until(lk, __t) == cv_status::no_timeout;
    if (__count_ == 0)
    {
        __count_ = 1;
        __id_ = __id;
        return true;
    }
    return false;
}

#endif //_LIBCUDACXX_HAS_THREAD_API_CUDA

template <class _L0, class _L1> _LIBCUDACXX_INLINE_VISIBILITY
int
try_lock(_L0& __l0, _L1& __l1)
{
    unique_lock<_L0> __u0(__l0, try_to_lock);
    if (__u0.owns_lock())
    {
        if (__l1.try_lock())
        {
            __u0.release();
            return -1;
        }
        else
            return 1;
    }
    return 0;
}

#ifndef _LIBCUDACXX_CXX03_LANG

template <class _L0, class _L1, class _L2, class... _L3> _LIBCUDACXX_INLINE_VISIBILITY
int
try_lock(_L0& __l0, _L1& __l1, _L2& __l2, _L3&... __l3)
{
    int __r = 0;
    unique_lock<_L0> __u0(__l0, try_to_lock);
    if (__u0.owns_lock())
    {
        __r = try_lock(__l1, __l2, __l3...);
        if (__r == -1)
            __u0.release();
        else
            ++__r;
    }
    return __r;
}

#endif  // _LIBCUDACXX_CXX03_LANG

template <class _L0, class _L1> _LIBCUDACXX_INLINE_VISIBILITY
void
lock(_L0& __l0, _L1& __l1)
{
    while (true)
    {
        {
            unique_lock<_L0> __u0(__l0);
            if (__l1.try_lock())
            {
                __u0.release();
                break;
            }
        }
        __libcpp_thread_yield();
        {
            unique_lock<_L1> __u1(__l1);
            if (__l0.try_lock())
            {
                __u1.release();
                break;
            }
        }
        __libcpp_thread_yield();
    }
}

#ifndef _LIBCUDACXX_CXX03_LANG

template <class _L0, class _L1, class _L2, class ..._L3> _LIBCUDACXX_INLINE_VISIBILITY
void
__lock_first(int __i, _L0& __l0, _L1& __l1, _L2& __l2, _L3& ...__l3)
{
    while (true)
    {
        switch (__i)
        {
        case 0:
            {
                unique_lock<_L0> __u0(__l0);
                __i = try_lock(__l1, __l2, __l3...);
                if (__i == -1)
                {
                    __u0.release();
                    return;
                }
            }
            ++__i;
            __libcpp_thread_yield();
            break;
        case 1:
            {
                unique_lock<_L1> __u1(__l1);
                __i = try_lock(__l2, __l3..., __l0);
                if (__i == -1)
                {
                    __u1.release();
                    return;
                }
            }
            if (__i == sizeof...(_L3) + 1)
                __i = 0;
            else
                __i += 2;
            __libcpp_thread_yield();
            break;
        default:
            __lock_first(__i - 2, __l2, __l3..., __l0, __l1);
            return;
        }
    }
}

template <class _L0, class _L1, class _L2, class ..._L3>
inline _LIBCUDACXX_INLINE_VISIBILITY
void
lock(_L0& __l0, _L1& __l1, _L2& __l2, _L3& ...__l3)
{
    __lock_first(0, __l0, __l1, __l2, __l3...);
}

template <class _L0>
inline _LIBCUDACXX_INLINE_VISIBILITY
void __unlock(_L0& __l0) {
    __l0.unlock();
}

template <class _L0, class _L1>
inline _LIBCUDACXX_INLINE_VISIBILITY
void __unlock(_L0& __l0, _L1& __l1) {
    __l0.unlock();
    __l1.unlock();
}

template <class _L0, class _L1, class _L2, class ..._L3>
inline _LIBCUDACXX_INLINE_VISIBILITY
void __unlock(_L0& __l0, _L1& __l1, _L2& __l2, _L3&... __l3) {
    __l0.unlock();
    __l1.unlock();
    _CUDA_VSTD::__unlock(__l2, __l3...);
}

#endif  // _LIBCUDACXX_CXX03_LANG

#if _LIBCUDACXX_STD_VER > 14
template <class ..._Mutexes>
class _LIBCUDACXX_TEMPLATE_VIS scoped_lock;

template <>
class _LIBCUDACXX_TEMPLATE_VIS scoped_lock<> {
public:
    explicit scoped_lock() {}
    ~scoped_lock() = default;

    _LIBCUDACXX_INLINE_VISIBILITY
    explicit scoped_lock(adopt_lock_t) {}

    scoped_lock(scoped_lock const&) = delete;
    scoped_lock& operator=(scoped_lock const&) = delete;
};

template <class _Mutex>
class _LIBCUDACXX_TEMPLATE_VIS _LIBCUDACXX_THREAD_SAFETY_ANNOTATION(scoped_lockable) scoped_lock<_Mutex> {
public:
    typedef _Mutex  mutex_type;
private:
    mutex_type& __m_;
public:
    _LIBCUDACXX_INLINE_VISIBILITY explicit scoped_lock(mutex_type & __m) _LIBCUDACXX_THREAD_SAFETY_ANNOTATION(acquire_capability(__m))
        : __m_(__m) {__m_.lock();}

    _LIBCUDACXX_INLINE_VISIBILITY ~scoped_lock() _LIBCUDACXX_THREAD_SAFETY_ANNOTATION(release_capability()) {__m_.unlock();}

    _LIBCUDACXX_INLINE_VISIBILITY
    _LIBCUDACXX_INLINE_VISIBILITY explicit scoped_lock(adopt_lock_t, mutex_type& __m) _LIBCUDACXX_THREAD_SAFETY_ANNOTATION(requires_capability(__m))
        : __m_(__m) {}

    scoped_lock(scoped_lock const&) = delete;
    scoped_lock& operator=(scoped_lock const&) = delete;
};

template <class ..._MArgs>
class _LIBCUDACXX_TEMPLATE_VIS scoped_lock
{
    static_assert(sizeof...(_MArgs) > 1, "At least 2 lock types required");
    typedef tuple<_MArgs&...> _MutexTuple;

public:
    _LIBCUDACXX_INLINE_VISIBILITY
    explicit scoped_lock(_MArgs&... __margs)
      : __t_(__margs...)
    {
        _CUDA_VSTD::lock(__margs...);
    }

    _LIBCUDACXX_INLINE_VISIBILITY
    scoped_lock(adopt_lock_t, _MArgs&... __margs)
        : __t_(__margs...)
    {
    }

    _LIBCUDACXX_INLINE_VISIBILITY
    ~scoped_lock() {
        typedef typename __make_tuple_indices<sizeof...(_MArgs)>::type _Indices;
        __unlock_unpack(_Indices{}, __t_);
    }

    scoped_lock(scoped_lock const&) = delete;
    scoped_lock& operator=(scoped_lock const&) = delete;

private:
    template <size_t ..._Indx>
    _LIBCUDACXX_INLINE_VISIBILITY
    static void __unlock_unpack(__tuple_indices<_Indx...>, _MutexTuple& __mt) {
        _CUDA_VSTD::__unlock(_CUDA_VSTD::get<_Indx>(__mt)...);
    }

    _MutexTuple __t_;
};

#endif // _LIBCUDACXX_STD_VER > 14
#endif // !_LIBCUDACXX_HAS_NO_THREADS

template<int _Sco>
struct _LIBCUDACXX_TEMPLATE_VIS __once_flag_base;

#ifndef _LIBCUDACXX_CXX03_LANG

template<int _Sco, class _Callable, class... _Args>
_LIBCUDACXX_INLINE_VISIBILITY
void call_once(__once_flag_base<_Sco>&, _Callable&&, _Args&&...);

#else  // _LIBCUDACXX_CXX03_LANG

template<int _Sco, class _Callable>
_LIBCUDACXX_INLINE_VISIBILITY
void call_once(__once_flag_base<_Sco>&, _Callable&);

template<int _Sco, class _Callable>
_LIBCUDACXX_INLINE_VISIBILITY
void call_once(__once_flag_base<_Sco>&, const _Callable&);

#endif  // _LIBCUDACXX_CXX03_LANG

template<int _Sco>
struct _LIBCUDACXX_TEMPLATE_VIS __once_flag_base
{
    _LIBCUDACXX_INLINE_VISIBILITY
    _LIBCUDACXX_CONSTEXPR
        __once_flag_base() _NOEXCEPT : __state_(0) {}

#if defined(_LIBCUDACXX_ABI_MICROSOFT)
    typedef uintptr_t _State_data_type;
#else
    typedef unsigned long _State_data_type;
#endif

    using _State_type = atomic<_State_data_type>;
    _State_type __state_;

private:
    __once_flag_base(const __once_flag_base&); // = delete;
    __once_flag_base& operator=(const __once_flag_base&); // = delete;
};

using once_flag = __once_flag_base<0>;

#ifndef _LIBCUDACXX_CXX03_LANG

template <class _Fp>
class __call_once_param
{
    _Fp& __f_;
public:
    _LIBCUDACXX_INLINE_VISIBILITY
    explicit __call_once_param(_Fp& __f) : __f_(__f) {}

    _LIBCUDACXX_INLINE_VISIBILITY
    void operator()()
    {
        typedef typename __make_tuple_indices<tuple_size<_Fp>::value, 1>::type _Index;
        __execute(_Index());
    }

private:
    template <size_t ..._Indices>
    _LIBCUDACXX_INLINE_VISIBILITY
    void __execute(__tuple_indices<_Indices...>)
    {
        __invoke(_CUDA_VSTD::get<0>(_CUDA_VSTD::move(__f_)), _CUDA_VSTD::get<_Indices>(_CUDA_VSTD::move(__f_))...);
    }
};

#else

template <class _Fp>
class __call_once_param
{
    _Fp& __f_;
public:
    _LIBCUDACXX_INLINE_VISIBILITY
    explicit __call_once_param(_Fp& __f) : __f_(__f) {}

    _LIBCUDACXX_INLINE_VISIBILITY
    void operator()()
    {
        __f_();
    }
};

#endif

template <class _Fp> _LIBCUDACXX_INLINE_VISIBILITY 
void __call_once_proxy(void* __vp)
{
    __call_once_param<_Fp>* __p = static_cast<__call_once_param<_Fp>*>(__vp);
    (*__p)();
}

#ifdef _LIBCUDACXX_INLINE_THREADING
template<int _Sco>
inline _LIBCUDACXX_INLINE_VISIBILITY void __call_once(volatile typename __once_flag_base<_Sco>::_State_type& __s, void* __p,
                                                      void (* __f)(void*))
    { 
        typename __once_flag_base<_Sco>::_State_data_type __once_expect = 0;
        if(__s.compare_exchange_strong(__once_expect, typename __once_flag_base<_Sco>::_State_data_type(1), memory_order_acquire))
        {
            __f(__p);
            __s.store(~typename __once_flag_base<_Sco>::_State_data_type(0), memory_order_release);
            __s.notify_all();
        }
        else if(__once_expect == 1)
            __s.wait(__once_expect);
    }
#else
_LIBCUDACXX_FUNC_VIS void __call_once(volatile once_flag::_State_type& __s, void* __p,
                                      void (* __f)(void*));
#endif

#ifndef _LIBCUDACXX_CXX03_LANG

template<int _Sco, class _Callable, class... _Args>
inline _LIBCUDACXX_INLINE_VISIBILITY
void
call_once(__once_flag_base<_Sco>& __flag, _Callable&& __func, _Args&&... __args)
{
    if (__flag.__state_.load(memory_order_acquire) != ~typename __once_flag_base<_Sco>::_State_data_type(0))
    {
        typedef tuple<_Callable&&, _Args&&...> _Gp;
        _Gp __f(_CUDA_VSTD::forward<_Callable>(__func), _CUDA_VSTD::forward<_Args>(__args)...);
        __call_once_param<_Gp> __p(__f);
        __call_once<_Sco>(__flag.__state_, &__p, &__call_once_proxy<_Gp>);
    }
}

#else  // _LIBCUDACXX_CXX03_LANG

template<class _Callable>
inline _LIBCUDACXX_INLINE_VISIBILITY
void
call_once(int _Sco, __once_flag_base<_Sco>& __flag, _Callable& __func)
{
    if (__flag.__state_.load(memory_order_acquire) != ~typename __once_flag_base<_Sco>::_State_data_type(0))
    {
        __call_once_param<_Callable> __p(__func);
        __call_once<_Sco>(__flag.__state_, &__p, &__call_once_proxy<_Callable>);
    }
}

template<class _Callable>
inline _LIBCUDACXX_INLINE_VISIBILITY
void
call_once(int _Sco, __once_flag_base<_Sco>& __flag, const _Callable& __func)
{
    if (__flag.__state_.load(memory_order_acquire) != ~typename __once_flag_base<_Sco>::_State_data_type(0))
    {
        __call_once_param<const _Callable> __p(__func);
        __call_once<_Sco>(__flag.__state_, &__p, &__call_once_proxy<const _Callable>);
    }
}

#endif  // _LIBCUDACXX_CXX03_LANG

_LIBCUDACXX_END_NAMESPACE_STD

#ifndef __cuda_std__
_LIBCUDACXX_POP_MACROS
#endif

#endif  // _LIBCUDACXX_MUTEX
